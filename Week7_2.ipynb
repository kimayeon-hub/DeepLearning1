{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+/AqBuRO2Ak4ZjvMbirUN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimayeon-hub/DeepLearning1/blob/main/Week7_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 지도학습 결과의 분석 방법"
      ],
      "metadata": {
        "id": "fc1e0-CnU_k3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습과 테스트\n",
        "- 지도학습 알고리즘을 통한 학습\n",
        "  - 학습된 모델 획득\n",
        "- 학습된 모델과 테스트 데이터를 사용하여 예측\n",
        "  - 예측된 결과와 (테스트 데이터의) 정답 데이터를 사용하여 평가"
      ],
      "metadata": {
        "id": "YKdKLe6dVH7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정확도\n",
        "> 예측 결과와 정답을 비교하면서 TN, FP, FN, TP가 몇 개가 있는지 count하기\n",
        "\n",
        "- 정확도를 나타내는 다양한 지표\n",
        "  - 정확도 (Accuracy)\n",
        "    - CA(classification accuracy) = (TP + TN) / (P + N)\n",
        "    - CA = T / (T + F)\n",
        "  - 정밀도\n",
        "    - Precision = TP / (TP + **FP**)\n",
        "    > FP의 값이 늘어날 수록, precision이 작아짐 <br>\n",
        "    > precision을 통해서 FP가 얼마나 늘어났느냐를 알 수 있음\n",
        "  - 재현율\n",
        "    - Recall = TP / (TP + **FN**)\n",
        "    > FN의 값이 늘어날 수록, recall이 작아짐 <br>\n",
        "    > recall을 통해서 FN이 얼마나 늘어났느냐를 알 수 있음\n",
        "  - F1 score\n",
        "    - 2 / (1/TP + 1/FP)\n",
        "    > precision과 recall을 조화평균(역수를 취해서 평균을 취한 다음, 다시 역수를 취함)을 낸 것 <br>\n",
        "    > precision과 recall을 통해서 FP와 FN을 평균을 내려는 것\n",
        "\n",
        "\n",
        "> 왜 accuracy말고도 다른 것을 사용하여 분석을 하느냐?\n",
        "- accuracy만으로 분석하면 분석을 잘 못 할 수 있음\n",
        "- 에러가 어디에 몰려 있는지 알 수 없음\n",
        "- 그래서 precision과 recall을 사용해서 자세하게 분석을 하는 것\n",
        "\n",
        "\n",
        "> CA, F1, Precision, Recall의 값이 다 비슷하다면, 오류가 고르게 났다고 분석할 수 있음\n",
        "\n",
        "\n",
        "> 용어\n",
        "- P: **정답** 데이터에서 **1**의 개수\n",
        "- N: **정답** 데이터에서의 **0**의 개수\n",
        "- TP: 예측결과가 **1**이면서, **정답**인 샘플의 개수\n",
        "- FP: 예측결과가 **1**이면서, **오답**인 샘플의 개수\n",
        "- TN: 예측결과가 **0**이면서, **정답**인 샘플의 개수\n",
        "- FN: 예측결과가 **0**이면서, **오답**인 샘플의 개수\n",
        "- T: 예측결과가 **정답**인 샘플의 개수\n",
        "- F: 예측결과가 **오답**인 샘플의 개수"
      ],
      "metadata": {
        "id": "dK8uTsEVVHbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 혼동행렬 (Confusion Matrix)\n",
        "\n",
        "|      |     | 예측 | 예측 |\n",
        "|------|-----|------|------|\n",
        "|      |     |   0  |   1  |\n",
        "| 정답 |  0  |  TN  |  FP  |\n",
        "| 정답 |  1  |  FN  |  TP  |\n",
        "\n",
        "\n",
        "- 정확도 (Accuary)\n",
        "  - T / (T + F)\n",
        "  - ([00] + [11] + [22]) / (전체 데이터의 개수)\n",
        "- Precision & Recall 계산 공식\n",
        "  - Precision = TP / (TP + FP)\n",
        "  - Recall = TP / (TP + FN)\n",
        "  - F1 score = 2 / (1/TP + 1/FP)\n",
        "\n",
        "<br>\n",
        "\n",
        "|      |     | 예측 | 예측 | 예측 |\n",
        "|------|-----|------|------|------|\n",
        "|      |     |   0  |   1  |   2  |\n",
        "| 정답 |  0  |   8  |   0  |   2  |\n",
        "| 정답 |  1  |   1  |   9  |   0  |\n",
        "| 정답 |  2  |   0  |   0  |  10  |\n",
        "\n",
        "\n",
        "- 클래스 0에 대한 Rrecision & Recall\n",
        "  - Precision = [00] / ([00] + [10] + [20])\n",
        "  - Recall = [00] / ([00] + [01] + [02])\n",
        "- 클래스 1에 대한 Precision & Recall\n",
        "  - Precision = [11] / ([11] + [01] + [21])\n",
        "  - Recall = [11] / ([11] + [10] + [12])\n",
        "- 클래스 2에 대한 Precision & Recall\n",
        "  - Precision = [22] / ([22] + [02] + [12])\n",
        "  - Recall = [22] / ([22] + [20] + [21])\n",
        "- 전체 클래스에 대한 Precison & Recall\n",
        "  - 각 패턴별 Precision & Recall의 평균\n"
      ],
      "metadata": {
        "id": "Fm8aAX17X9QP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AUC (Area Under Curve)\n",
        "- TPR & FPR\n",
        "  - TPR: True Positive Ratio\n",
        "    - TP / P\n",
        "  - FPR: False Positive Ratio\n",
        "    - FP / N\n",
        "    - Negative 중에서 Positive라는 에러를 얼마나 발생시켰냐를 보는 것\n",
        "- 최종 예측치\n",
        "  - 최종 예측을 위해, 로지스틱 회귀분석 등을 사용하여 예측한 수치를 0, 1로 바꾸는 과정이 필요\n",
        "- 임계치 조정과 AUC\n",
        "  - 0.5를 기준(임계치)으로 하는 것이 일반적이나, 이를 조정하면 1 (positive)로 예측하는 비율을 조정할 수 있음\n",
        "  - 임계치가 0이면 모든 경우를 Positive로 인식\n",
        "  - 임계치가 커질수록 Positive로 인식하는 데이터 샘플의 수가 적어짐\n",
        "    - FP 에러 감소, FN 에러 증가\n",
        "    - 임계치를 조정하면서 (FPR, TPR)을 계산하여 그래프(커브)로 나타냄\n",
        "    - AUC: 커브 아래쪽 영역의 비율 (0 ~ 1)\n",
        "\n",
        "\n",
        "> threshold = 1 -> 모두 Negative로 예측 -> (0, 0) <br>\n",
        "> threshold = 0.9 -> 약간 positive로 예측(임계치가 높을수록 예측이 정답일 가능성이 높음) -> <br>\n",
        "> threshold = 0 -> 무조건 positive로 예측 (에러율(NT)이 높아짐, TP도 높아짐) -> (1, 1)\n",
        "\n",
        "\n",
        "> 좋은 모델일수록 1에 가까워져서 AUC가 높을수록 좋은 모델인것"
      ],
      "metadata": {
        "id": "voNenAALg4Ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-Fold Cross Validation\n",
        "- 일반적인 학습 모델의 검증\n",
        "  - Train-Test로 나누어 검증\n",
        "  - `ex` 7 : 3 등\n",
        "- N_Fold 교차 검증의 배경\n",
        "  - 데이터의 샘플 수가 적은 경우, 테스트 데이터의 수가 적어 검증의 신뢰도 하락\n",
        "  - `ex` 학습용 샘플 16개, 테스트 샘플 4개\n",
        "- N-Fold 교차 검증의 개념\n",
        "  - 전체 데이터를 N등분 한 다음, N - 1개를 학습에, 1개를 테스트로 사용\n",
        "  - 테스트 데이터를 바꾸어 가며 학습-테스트를 N번 반복하여, 모든 데이터가 테스트에 사용되도록 조정\n",
        "  - 나온 결과를 취합하여 최종 결과 도출\n",
        "- 장점\n",
        "  - 데이터 샘플 수가 적은 경우에, 학습용 데이터 수를 최대화 할 수 있음\n",
        "  - 각 직합의 데이터가 서로 독립인 경우 검증결과의 신뢰성 향상 (`ex` 서로 다른 사람의 얼굴 데이터)\n",
        "- 단점\n",
        "  - 검증에 소요되는 시간 증가\n",
        "  - 한 집합에 속하는 데이터 수가 너무 적고, 각 집합의 데이터가 서로 움립이 아닌 경우, 테스트 결과를 신뢰하기 어려움"
      ],
      "metadata": {
        "id": "H15QWD47kMmK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O9EzjWyAl3ha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}